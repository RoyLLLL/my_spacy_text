import pandas as pd
import json
import os
#os.chdir(r'C:\Users\\Downloads')
from tqdm import tqdm
import spacy
from spacy.tokens import DocBin


with open('annotations.json', 'r') as f:
    data = json.load(f)

#print(data)

train_data = data['annotations']
train_data = [tuple(i) for i in train_data]

TRAIN_DATA = []
for text, annotations in train_data:
    entities = []
    for start, end, label in annotations['entities']:
        entities.append((start, end, label))
    TRAIN_DATA.append((text.strip(), {'entities': entities}))


print(TRAIN_DATA)

nlp = spacy.load("en_core_web_sm") # load other spacy model

db = DocBin()
for text, annot in tqdm(TRAIN_DATA): # data in previous format
    doc = nlp.make_doc(text) # create doc object from text
    ents = []
    for start, end, label in annot["entities"]: # add character indexes
        span = doc.char_span(start, end, label=label, alignment_mode="contract")
        if span is None:
            print("Skipping entity")
        else:
            ents.append(span)
    doc.ents = ents # label the text with the ents
    db.add(doc)

os.chdir(r'./') #命令将当前工作目录更改为所需目录，这里需要将工作目录设置为保存数据的路径。
db.to_disk("./train.spacy")